{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/Administrator/Desktop/移动广告反欺诈算法挑战/移动广告反欺诈算法挑战赛-0621/移动广告反欺诈算法挑战赛/round1_iflyad_anticheat_traindata.txt',encoding='utf-8',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('C:/Users/Administrator/Desktop/移动广告反欺诈算法挑战/移动广告反欺诈算法挑战赛-0621/移动广告反欺诈算法挑战赛/round1_iflyad_anticheat_testdata_feature.txt',encoding='utf-8',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#缺失值处理\n",
    "#city用众数填充\n",
    "df['city'] = df['city'].fillna('北京市')\n",
    "#lan用众数填充\n",
    "language = ['zh-CN','Zh-CN', 'zh-cn', 'cn', 'zh_CN', 'zh', 'ZH', 'CN', 'tw','zh_CN_#Hans','zh-TW','zh-HK','zh-US','zh_HK_#Hant',\n",
    "           'zh-MO','zh-','zh_TW']\n",
    "df.loc[df['lan'].isin(language),'lan'] = 'cn'\n",
    "df['lan'] = df['lan'].fillna('cn')\n",
    "#make用众数填充\n",
    "df['make'] = df['make'].fillna('oppo')\n",
    "#model用众数填充\n",
    "df['model'] = df['model'].fillna('PBAMOO')\n",
    "#osv用众数填充\n",
    "df['osv'] = df['osv'].fillna('8.1.0')\n",
    "#ver用众数填充\n",
    "df['ver'] = df['ver'].fillna('30927000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不明白含义的特征，先删除\n",
    "df.drop(['idfamd5','imeimd5','adidmd5','adunitshowid','openudidmd5','pkgname','macmd5','mediashowid','sid','h','w','reqrealip','ip',\n",
    "        'ver','os'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#运营商变量替换\n",
    "df.loc[df['carrier'] == 46000,'carrier'] = 1\n",
    "df.loc[df['carrier'] == 46001,'carrier'] = 2\n",
    "df.loc[df['carrier'] == 46003,'carrier'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对nginxtime标准化\n",
    "df['nginxtime_std'] = (df['nginxtime'] - df['nginxtime'].mean())/df['nginxtime'].std()\n",
    "df = df.drop('nginxtime',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['make'] = df['make'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = ['zh-CN','Zh-CN', 'zh-cn', 'cn', 'zh_CN', 'zh', 'ZH', 'CN', 'tw','zh_CN_#Hans','zh-TW','zh-HK','zh-US','zh_HK_#Hant',\n",
    "           'zh-MO','zh-','zh_TW']\n",
    "df.loc[df['lan'].isin(language),'lan'] = 'cn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将分类太多的特征取数量排前20的值，其他变成others，方便one-hot\n",
    "citys = []\n",
    "for i in df['city'].value_counts().head(20).index:\n",
    "    citys.append(i)\n",
    "df.loc[~df['city'].isin(citys),'city'] = 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "makes = []\n",
    "for i in df['make'].value_counts().head(20).index:\n",
    "    makes.append(i)\n",
    "df.loc[~df['make'].isin(makes),'make'] = 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in df['model'].value_counts().head(20).index:\n",
    "    models.append(i)\n",
    "df.loc[~df['model'].isin(models),'model'] = 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "osvs = []\n",
    "for i in df['osv'].value_counts().head(20).index:\n",
    "    osvs.append(i)\n",
    "df.loc[~df['osv'].isin(osvs),'osv'] = 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot处理\n",
    "dm_city = pd.get_dummies(df['city'], prefix='city')\n",
    "dm_lan = pd.get_dummies(df['lan'], prefix='lan')\n",
    "dm_make = pd.get_dummies(df['make'], prefix='make')\n",
    "dm_model = pd.get_dummies(df['model'], prefix='model')\n",
    "dm_osv = pd.get_dummies(df['osv'], prefix='osv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df,dm_city,dm_lan,dm_make,dm_model,dm_osv],axis=1)\n",
    "df.drop(['city','lan','make','model','osv'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拆回train和test\n",
    "train_data = df[0:1000000]\n",
    "test_data = df[1000000:].drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(['label'],axis=1)\n",
    "y = train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = XGBClassifier()\n",
    "model3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86192\n"
     ]
    }
   ],
   "source": [
    "print(model3.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LR()\n",
    "model1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=20,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RFC(n_estimators=50, max_depth=None,min_samples_split=20, random_state=0)\n",
    "model2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.901445\n"
     ]
    }
   ],
   "source": [
    "print(model2.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model2.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = test['sid']\n",
    "result = pd.DataFrame({'sid':sid,'label':y_predict})\n",
    "result.to_csv('result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
